{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\mauro\\Downloads\\mido-master\")\n",
    "sys.path.append(r\"C:\\Users\\mauro\\Downloads\\pretty-midi-master\")\n",
    "\n",
    "import mido\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "#Grabs files \n",
    "for entry in os.scandir('Midi_files'):\n",
    "    if entry.is_file():\n",
    "        files.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = []\n",
    "end_time = []\n",
    "#determines timestamp\n",
    "for midi in files:\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi)\n",
    "    for instrument in midi_data.instruments:\n",
    "        for i,note in enumerate(instrument.notes):\n",
    "                duration.append(note.end - note.start)\n",
    "        end_time.append(note.end)\n",
    "        break\n",
    "duration.sort()\n",
    "bucket_length = int(len(duration)/4)\n",
    "duration_bucket_1 = bucket_length\n",
    "duration_bucket_2 = bucket_length * 2\n",
    "duration_bucket_3 = bucket_length * 3\n",
    "\n",
    "step = duration[duration_bucket_1]\n",
    "step = round(step,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import utils as np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten, Dropout, Activation\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8164, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "song = []\n",
    "#grabs notes from songs\n",
    "for midi in files:\n",
    "    current_step = 0.0\n",
    "    current_index = 0\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi)\n",
    "\n",
    "    note = []\n",
    "    for instrument in midi_data.instruments:\n",
    "        if(instrument.name==\"Drum kit 2\"):\n",
    "            continue\n",
    "        if not instrument.is_drum:\n",
    "            for n in instrument.notes:\n",
    "                #determines duration lenght and timestamp bucket for each\n",
    "                time = n.end - n.start\n",
    "                if (time < duration[duration_bucket_1]):\n",
    "                    time = 1\n",
    "                elif (time < duration[duration_bucket_2]):\n",
    "                    time = 2\n",
    "                elif (time < duration[duration_bucket_3]):\n",
    "                    time = 3\n",
    "                else:\n",
    "                    time = 4\n",
    "                \n",
    "                \n",
    "                note.append(time)\n",
    "                note.append(n.pitch)\n",
    "                note.append(n.velocity)\n",
    "                \n",
    "                #converts note into one value string\n",
    "                song.append('.'.join(str(i) for i in note))\n",
    "                note.clear()\n",
    "               \n",
    "            break\n",
    "#number of note types\n",
    "n_vocab = len(set(song))\n",
    "#collection of each note_type\n",
    "pitchnames = sorted(set(item for item in song))   \n",
    "\n",
    "#gives an int value to each note type\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "#main input vector\n",
    "network_input = []\n",
    "#output vector\n",
    "network_output = []\n",
    "#notes in sequence\n",
    "sequence_length = 100\n",
    "\n",
    "#sets up the list of 100 note sequences\n",
    "for i in range(0, len(song) - sequence_length, 1):\n",
    "    sequence_in = song[i:i + sequence_length]\n",
    "    sequence_out = song[i + sequence_length]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "    \n",
    "#how many total sequences    \n",
    "n_patterns = len(network_input)\n",
    "\n",
    "#converts to lstm readable matrix\n",
    "network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "#normalizes note values\n",
    "network_input = network_input / float(n_vocab)\n",
    "\n",
    "network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "print(network_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100, 1024)         4202496   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 1024)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 1024)         8392704   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 102400)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               52429312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1351)              693063    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1351)              0         \n",
      "=================================================================\n",
      "Total params: 65,717,575\n",
      "Trainable params: 65,717,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Building the model architecture\n",
    "#network_input.shape=(time, pitch, velocity)\n",
    "model = Sequential()  \n",
    "model.add(LSTM(1024, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))  \n",
    "model.add(Dropout(0.2))                                                # prevents overfitting\n",
    "model.add(LSTM(1024, return_sequences=True))  \n",
    "model.add(Flatten())  \n",
    "model.add(Dense(512))  \n",
    "model.add(Dropout(0.3))  \n",
    "model.add(Dense(n_vocab))                                              # each input node becomes connected to output node\n",
    "model.add(Activation('softmax'))  \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')    # optimizer= how it learns while loss= how well it learns\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "    \n",
    "# Create checkpoint to save the best model weights.\n",
    "filepath = filepath = r\"C:\\\\Users\\\\mauro\\\\Downloads\\\\weights-improvement--{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
    "    \n",
    "model.fit(network_input, network_output, epochs=200, batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore from here down until top works\n",
    "'''\n",
    "# Building the model architecture\n",
    "model = Sequential()  \n",
    "model.add(LSTM(1024, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))  \n",
    "model.add(Dropout(0.2))                                                # prevents overfitting\n",
    "model.add(LSTM(1024, return_sequences=True))  \n",
    "model.add(Flatten())  \n",
    "model.add(Dense(512))  \n",
    "model.add(Dropout(0.3))  \n",
    "model.add(Dense(n_vocab))                                              # each input node becomes connected to output node\n",
    "model.add(Activation('softmax'))  \n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')    # optimizer= how it learns while loss= how well it learns\n",
    "\n",
    "model.load_weights(r\"C:\\\\Users\\\\mauro\\\\Downloads\\\\weights-improvement-bigger.hdf5\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train_network():  \n",
    "    epochs = 200 \n",
    "    \n",
    "    notes = get_notes()  \n",
    "    print('Notes processed') \n",
    "    \n",
    "    n_vocab = len(set(notes))  \n",
    "    print('Vocab generated')\n",
    "    \n",
    "    # create input and output sequences\n",
    "    network_in, network_out = prepare_sequences(notes, n_vocab)  \n",
    "    print('Input and Output processed')  \n",
    "    \n",
    "    model = create_network(network_in, n_vocab)  \n",
    "    print('Model created') \n",
    "    \n",
    "    return model  \n",
    "\n",
    "    print('Training in progress')  \n",
    "    \n",
    "    train(model, network_in, network_out, epochs)  \n",
    "    print('Training completed')  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "#train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def generate_notes(model, network_input, pitchnames, n_vocab):  \n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"  \n",
    "   # Pick a random integer  \n",
    "    start = np.random.randint(0, len(network_input)-1)  \n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))  \n",
    "    # pick a random sequence from the input as a starting point for the prediction  \n",
    "    pattern = network_input[start]  \n",
    "    prediction_output = []  \n",
    "    print('Generating notes........')  \n",
    "    # generate 500 notes  \n",
    "    for note_index in range(500):  \n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))  \n",
    "        prediction_input = prediction_input / float(n_vocab)  \n",
    "        prediction = model.predict(prediction_input, verbose=0)  \n",
    "         # Predicted output is the argmax(P(h|D))  \n",
    "        index = np.argmax(prediction)  \n",
    "         # Mapping the predicted interger back to the corresponding note  \n",
    "        result = int_to_note[index]  \n",
    "         # Storing the predicted output  \n",
    "        prediction_output.append(result)  \n",
    "        pattern.append(index)  \n",
    "         # Next input to the model  \n",
    "        pattern = pattern[1:len(pattern)]  \n",
    "    print('Notes Generated...')  \n",
    "    return prediction_output  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### Converts the predicted output to midi format  \n",
    "#create_midi(prediction_output)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
